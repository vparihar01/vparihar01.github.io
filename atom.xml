<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>Rubyist, Hacker, DevOps</title>
 <link href="http://vparihar01.github.io/" rel="self"/>
 <link href="http://vparihar01.github.io"/>
 <updated>2014-06-20T14:22:43+05:30</updated>
 <id>http://vparihar01.github.io</id>
 <author>
   <name>Vivek Parihar</name>
   <email>vivek@weboniselab.com</email>
 </author>

 
 <entry>
   <title>3 Years To Success</title>
   <link href="http://vparihar01.github.io/englightenments/2014/01/29/3-years-to-success"/>
   <updated>2014-01-29T00:00:00+05:30</updated>
   <id>http://vparihar01.github.io/englightenments/2014/01/29/3-years-to-success</id>
   <content type="html">&lt;h4 id='simba_icon_background'&gt;&lt;img alt='simba icon' src='/assets/themes/twitter/bootstrap/img/simba.jpeg' /&gt; Background&lt;/h4&gt;

&lt;p&gt;From D-hostel in the Bharati Vidyapeeth campus in Katraj, Pune to the centre stage of some of the most prestigious technology events, its been a journey worth every bit of it.&lt;/p&gt;

&lt;p&gt;Born into a business-oriented family, entrepreneurship was in my blood. I grew up under the influence of my father, who himself is an accomplished Civil Engineer with extraordinary problem solving skills and my mother who till date is the most motivated person I have ever known. Leadership was in my lineage, and my childhood had toughened me enough to take the world head on.&lt;/p&gt;

&lt;p&gt;From a very early age I was helping out in my father’s construction business, that gave me an insight into the world of workforce management and execution. Getting things done is the first and the foremost attribute of a successful entrepreneur. A close second, is the ability to sell it. As I saw projects after projects getting built in front of me, and each one with a unique set of problems, each having an even more unique set of solutions that were seldom from a textbook and more from experience and genius, it developed my acumen for finding ways out of difficult situations and taking calculated risks.&lt;/p&gt;
&lt;hr /&gt;
&lt;h4 id='smiley_icon_thats_me'&gt;&lt;img alt='smiley icon' src='/assets/themes/twitter/bootstrap/img/crazy_smiley.jpeg' /&gt; That&amp;#8217;s Me!&lt;/h4&gt;

&lt;p&gt;I have always been good at making friends and enemies alike, and that helped me in taking unpopular but productive and progressive decisions that have a larger overall impact. The college life and especially heading the marketing team for the college festivals helped me in building my skills of finding the right partners for the right initiative.&lt;/p&gt;
&lt;hr /&gt;
&lt;h4 id='gaming_icon_the_gaming_phase'&gt;&lt;img alt='gaming icon' src='/assets/themes/twitter/bootstrap/img/I-Love-Gaming.jpeg' /&gt; The Gaming Phase&lt;/h4&gt;

&lt;p&gt;My journey into the web and software started with, not surprisingly, gaming. It was the age of massive &lt;a href='http://en.wikipedia.org/wiki/Multiplayer_online_game'&gt;multiplayer online games&lt;/a&gt;, and I really dig into it. Before I knew it, I was developing parts of these games with developers across the globe. By the time I was in second year of college, not only was I good at gaming, but was able to sustain myself independently.&lt;/p&gt;

&lt;p&gt;Internet had redefined the way we think, work and live. So, it made sense to work on it and build solutions that not only help people in getting things done faster but are also a viable business proposition. In third year of college itself, I started my own software development company along with a couple of classmates. Being the fastest technical hand in the team, I was able to gain a lot of experience in a short amount of time. The guidance from my siblings who were back then thriving in their careers in the various tech giants helped me give direction to our company on the technology front.&lt;/p&gt;
&lt;hr /&gt;
&lt;h4 id='weboman_icon_the_webonise_chapter'&gt;&lt;img alt='weboman icon' src='/assets/themes/twitter/bootstrap/img/weboman.jpg' /&gt; The Webonise Chapter&lt;/h4&gt;

&lt;p&gt;Apparently, there was something even bigger and better in store. As we moved on and found ourselves competing with a lot of established players in the market, it made sense to join hands with someone already out there. But it was difficult to find the environment I was looking for. If you want to create value you need to be part of an ecosystem that is based on strong principles and an open culture. That is when I got to know about &lt;strong&gt;Webonise Labs&lt;/strong&gt; from a very close friend.&lt;/p&gt;

&lt;p&gt;&lt;a href='http://www.webonise.com/'&gt;Webonise&lt;/a&gt; at that time was a 10 people company working out of a small office virtually invisible to the world. But the energy was amazing, the moment I stepped in and met the guys, it was like finding the reason that you keep looking for. They wanted to build something great, something exciting, something that will be a game changer. We started building products, that gave us a taste of the real world, and before we realised we were begin sought after by various local and international startups to help them in building their ideas and bringing them on the web.&lt;/p&gt;
&lt;hr /&gt;
&lt;h4 id='webonise_icon_growing_with_webonise'&gt;&lt;img alt='webonise icon' src='/assets/themes/twitter/bootstrap/img/webonise.jpeg' /&gt; Growing with Webonise&lt;/h4&gt;

&lt;p&gt;My skill and past experiences with technology helped me in building a great team of engineers and we were able to scale to multi million dollar projects within three years. The stress on quality and getting things done on time made sure that &lt;em&gt;&lt;a href='http://www.webonise.com/%27'&gt;Webonise Labs&lt;/a&gt; became a technology partner of various organisations around the world&lt;/em&gt;. We expanded operations to the US and partnered with companies in Europe and Canada and were able to provide complex solutions on niche technologies.&lt;/p&gt;
&lt;hr /&gt;
&lt;h4 id='weboman_icon__here_i_am'&gt;&lt;img alt='weboman icon' src='/assets/themes/twitter/bootstrap/img/proud_smiley.jpeg' /&gt; &amp;#8230; here I am.&lt;/h4&gt;

&lt;p&gt;Today, I am the &lt;strong&gt;Assistant Vice President of Engineering&lt;/strong&gt; at &lt;strong&gt;&lt;a href='http://www.webonise.com/'&gt;Webonise Labs&lt;/a&gt;&lt;/strong&gt;, creating products and building teams across continents. What I learned over time is that, its not just about creating business value, its about thought leadership. Its about giving back to the community and embracing change to grow and to always keep moving forward.&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>MongoDb scalability and high availability with Replica-Set</title>
   <link href="http://vparihar01.github.io/talks/2013/10/27/MongoDB-Scalability-and-High-Availabiltity-with-Replica-Sets"/>
   <updated>2013-10-27T00:00:00+05:30</updated>
   <id>http://vparihar01.github.io/talks/2013/10/27/MongoDB-Scalability-and-High-Availabiltity-with-Replica-Sets</id>
   <content type="html">&lt;p&gt;&lt;img alt='Smaller icon' src='/assets/themes/twitter/bootstrap/img/mongodb.png' /&gt; , as one of the trendy and most discussed technology, has raised huge user base recently.&lt;/p&gt;

&lt;p&gt;Most of the audience prefer practicing it or using it as back-end for their production running applications.&lt;/p&gt;

&lt;p&gt;First thought about &lt;em&gt;MongoDB&lt;/em&gt; usually tends to be another &lt;em&gt;No-SQL&lt;/em&gt; database. But a better glance pushed me to explore its functionality in-depth. Easy to use and unanimous in-built functionality made it far different than other No-SQL databases.&lt;/p&gt;

&lt;p&gt;Although, my consent is with every aspect and versatility of &lt;em&gt;MongoDB&lt;/em&gt;, yet I agree that it is not a silver bullet for all your problems. One has to be clear with the use case you want to put it in, while opting for MongoDB as a back-end.&lt;/p&gt;

&lt;p&gt;During the &lt;em&gt;MongoDB&lt;/em&gt; Meetup, I didn’t prefer discussing “&lt;em&gt;What is MongoDB&lt;/em&gt;” as that is something which has been taken care of by a lot of people rather, I attempted to elaborate the “&lt;strong&gt;10 reasons to love mongodb&lt;/strong&gt;” and how comfortably we can scale it at any given point of time.&lt;/p&gt;

&lt;h4 id='the_10_reasons'&gt;The 10 reasons:&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;Relatively easy to set up&lt;/li&gt;

&lt;li&gt;Quite fast&lt;/li&gt;

&lt;li&gt;Easily scalable&lt;/li&gt;

&lt;li&gt;High availability&lt;/li&gt;

&lt;li&gt;High performance&lt;/li&gt;

&lt;li&gt;Flexible schema&lt;/li&gt;

&lt;li&gt;Built-in sharding &amp;amp; replication&lt;/li&gt;

&lt;li&gt;Courses are excellent to start working as a developer/DBA.&lt;/li&gt;

&lt;li&gt;Deploy new instance on demand&lt;/li&gt;

&lt;li&gt;Base rather than ACID&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id='base_rather_than_acid'&gt;BASE rather than ACID&lt;/h4&gt;

&lt;p&gt;Usually large systems are based on CAP, rather than on &lt;em&gt;ACID&lt;/em&gt;, they are a &lt;em&gt;BASE&lt;/em&gt;!&lt;/p&gt;

&lt;h5 id='as_base_stands_for'&gt;As BASE stands for:&lt;/h5&gt;

&lt;p&gt;&lt;strong&gt;B&lt;/strong&gt;asically &lt;strong&gt;A&lt;/strong&gt;vailable - system seems to work all the time&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;S&lt;/strong&gt;oft State - it doesn&amp;#8217;t have to be consistent all the time&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;E&lt;/strong&gt;ventually Consistent - becomes consistent later&lt;/p&gt;

&lt;p&gt;Organizations nowadays tend to build their applications on &lt;em&gt;CAP &amp;amp; BASE&lt;/em&gt;, to name a few: &lt;em&gt;Google, Yahoo, Facebook, Amazon, eBay&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Amazon&lt;/strong&gt; popularized the concept of “&lt;em&gt;Eventual Consistency&lt;/em&gt;”.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Their definition is:&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The storage system guarantees that if no new updates are made to the object, eventually all accesses will return the last updated value.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id='my_personal_views'&gt;My personal views:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;I love Mongodb for its documents and collection concept&lt;/li&gt;

&lt;li&gt;Flexibility in schema design (JSON type document store)&lt;/li&gt;

&lt;li&gt;Scalability - Just add up nodes and it can scale horizontally quite well&lt;/li&gt;

&lt;li&gt;MongoDB has a niche use case regarding Big Data&lt;/li&gt;

&lt;li&gt;High Availability using replica-set&lt;/li&gt;

&lt;li&gt;As there is no concept for SQL or JOINs, hence! high performance&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;What else would you want from a Database, MongoDB is able to provide all at once!!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id='mongodb_scalability'&gt;MongoDb Scalability&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;Scalability&lt;/em&gt; is one of the complicated segments to be discussed and it&amp;#8217;s tough to make a general statement. MongoDb has Built in &lt;em&gt;Auto-sharding&lt;/em&gt; and &lt;em&gt;Replication&lt;/em&gt;.&lt;/p&gt;

&lt;h4 id='sharding'&gt;Sharding:&lt;/h4&gt;

&lt;p&gt;Each shard is an independent database and collectively they form one &lt;em&gt;single database&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;One of the much awaited features in &lt;em&gt;MongoDB 1.6&lt;/em&gt; is replica sets, MongoDB replication solution providing automatic failure and recovery.&lt;/p&gt;

&lt;h5 id='this_covers_'&gt;This covers -&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;What is Replica Set?&lt;/li&gt;

&lt;li&gt;Replication Process&lt;/li&gt;

&lt;li&gt;Advantaged of &lt;em&gt;Replica Set&lt;/em&gt; vs &lt;em&gt;Master/Slave&lt;/em&gt;&lt;/li&gt;

&lt;li&gt;How to set up replica set on Production Demo&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below is the &lt;strong&gt;presentation&lt;/strong&gt; on &lt;strong&gt;MongoDb&lt;/strong&gt; scalability and high availability with Replica-Set which is covered in MongoDB meetup by me, it is short and covered a lot of enlightened point which is really helpful for the people who are novice in MongoBb. &lt;iframe frameborder='0' height='356' src='http://www.slideshare.net/slideshow/embed_code/27617066' width='427'&gt; &lt;/iframe&gt;&lt;/p&gt;

&lt;h5 id='below_is_recorded_session_video'&gt;Below is recorded session video:&lt;/h5&gt;
&lt;iframe frameborder='0' height='500' src='http://www.youtube.com/embed/PSdru23y4hk' width='500'&gt;        &lt;/iframe&gt;
&lt;p&gt;During the session I tried to explain:”&lt;strong&gt;Setting up replica set on production environment&lt;/strong&gt;” through a video demo. Explanation gathered 3 instances which already have Mongo installed.&lt;/p&gt;

&lt;h5 id='this_tutorial_consists'&gt;This tutorial consists:&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;Setup the each instance of replica set&lt;/li&gt;

&lt;li&gt;Modify the mongodb.conf to include replica set information&lt;/li&gt;

&lt;li&gt;Configure the servers to include in replica set&lt;/li&gt;

&lt;li&gt;Cross checking, if we remove primary then secondary becomes primary or not.&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id='below_is_the_tutorial_video'&gt;Below is the tutorial video:&lt;/h5&gt;
&lt;iframe frameborder='0' height='500' src='http://www.youtube.com/embed/BFSGcBHcirU' width='500'&gt;        &lt;/iframe&gt;
&lt;blockquote&gt;
&lt;p&gt;I am sure from this port, you would&amp;#8217;ve found your own reason to love &lt;strong&gt;MongoDB&lt;/strong&gt;,&lt;/p&gt;
&lt;/blockquote&gt;</content>
 </entry>
 
 <entry>
   <title>Rails 3 Custom Validators</title>
   <link href="http://vparihar01.github.io/rails/2013/08/27/Rails-3-Custom-Validators"/>
   <updated>2013-08-27T00:00:00+05:30</updated>
   <id>http://vparihar01.github.io/rails/2013/08/27/Rails-3-Custom-Validators</id>
   <content type="html"></content>
 </entry>
 
 <entry>
   <title>How To Become Better Rubyist?</title>
   <link href="http://vparihar01.github.io/talks/2013/08/22/How-To-Become-Better-Rubyist"/>
   <updated>2013-08-22T00:00:00+05:30</updated>
   <id>http://vparihar01.github.io/talks/2013/08/22/How-To-Become-Better-Rubyist</id>
   <content type="html">&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Its simple!&lt;/strong&gt; Just keep your mind open to new things and keep learning(&lt;em&gt;even if its stupid and small&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;e.g. &lt;code&gt;print vs. puts&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Be patient&lt;/strong&gt;. It takes time. Self teaching is the best teaching. The Ruby Community, having an open source community of active and enthusiastic &lt;em&gt;rubyists&lt;/em&gt;, will help you while you learn. Share your knowledge and you will get twice in return.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Don&amp;#8217;t be Selffish :P&lt;/strong&gt; Don&amp;#8217;t learn with an intention to keep the knowledge to yourself. Learn so that one day you can give back to the community and make your own contributions.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Share your thoughts&lt;/strong&gt; Share your ideas and opinions towards ruby, and you will get interesting responses. Syntax is something just for the learning sake. What u really need to understand is there is more to it than meets the eye.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Discuss More&lt;/strong&gt; Discuss your experiences with other &lt;em&gt;rubyists&lt;/em&gt;, and listen to what they have to give in return. It will widen your outlook and expand your horizon.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;The moto of any great Rubyist is - &lt;strong&gt;Love&lt;/strong&gt;, &lt;strong&gt;Live&lt;/strong&gt;, &lt;strong&gt;Share&lt;/strong&gt;, &lt;strong&gt;Care&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Love Ruby!&lt;/strong&gt; But don&amp;#8217;t restrict yourself to just Ruby. &lt;em&gt;Explore!&lt;/em&gt;&lt;/li&gt;

&lt;li&gt;&lt;strong&gt;Work Hard!&lt;/strong&gt; But take your time off for a holiday.. &lt;em&gt;trust me you need it ;)&lt;/em&gt;&lt;/li&gt;

&lt;li&gt;&lt;strong&gt;Share!&lt;/strong&gt; You may become an inspiration for someone someday with your contribution.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</content>
 </entry>
 
 <entry>
   <title>Understanding Linux Cpu Or System Load And Check Or List Running Services</title>
   <link href="http://vparihar01.github.io/setup/2013/08/07/Understanding-Linux-CPU-or-System-Load-And-Check-or-List-Running-Services"/>
   <updated>2013-08-07T00:00:00+05:30</updated>
   <id>http://vparihar01.github.io/setup/2013/08/07/Understanding-Linux-CPU-or-System-Load-And-Check-or-List-Running-Services</id>
   <content type="html">
&lt;div id=&quot;preview_div&quot; xmlns=&quot;http://www.w3.org/1999/html&quot;&gt;&lt;p&gt;In this blog post I am trying to cover all the basic server related commands that are used by sys-admins on a daily basis.
    These might be very helpful for developers to get their hands on these commands. It would give devs a more in depth undertanding of the application memory and resource usage.
    I have tried to cover-:
    &lt;em&gt; Checking Running Services on Linux
    &lt;/em&gt; Checking and Understanding System Load on Linux
    * Checking Listening Ports&lt;/p&gt;
&lt;/br&gt;
&lt;h2 id=&quot;1-service&quot;&gt;1. Service&lt;/h2&gt;
&lt;p&gt;To check if services/programme is running -:
    To check if services is running we use command service for that particular job&lt;/p&gt;
&lt;h3 id=&quot;a-service-names&quot;&gt;A. Service names&lt;/h3&gt;
&lt;p&gt;The service command references are stored in the /etc/init.d directory.&lt;/p&gt;
&lt;p&gt;Distribution - apache is &lt;em&gt;apache2&lt;/em&gt; on Ubuntu.&lt;/p&gt;
&lt;h3 id=&quot;b-service-status&quot;&gt;B. Service status&lt;/h3&gt;
&lt;p&gt;The following example shows how to check the status of apache on Ubuntu using the service command.&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;Using service command &lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;~$ sudo service apache2 status
    Apache2 is running (pid 2855).
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
    &lt;li&gt;Using init.d scripts which are located in /etc/init.d folder&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;~$ /etc/init.d/apache2 status
    Apache2 is running (pid 2855).
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;c-service-command-list-all-running-services-on-ubuntu&quot;&gt;C. Service command - list all running services on Ubuntu&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;~$ service --status-all
    [ ? ]  acpid
    [ + ]  apache2
    [ - ]  fail2ban
    [ ? ]  fms
    [ + ]  mongodb
    [ ? ]  mysql
    [ - ]  postfix
    [ - ]  rsync
    [ ? ]  rsyslog
    [ ? ]  ssh
    [ ? ]  sudo
    [ ? ]  ufw
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;d-service-controllstartstop&quot;&gt;D. Service Control(start/stop)&lt;/h3&gt;
&lt;p&gt;To start the service -:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~$ sudo service apache2 start
    Starting apache2:                                            [  OK  ]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the application cannot be started the service command will report the failure and usually show a message explaining the reason.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~$ sudo service apache2 start
    Starting httpd: (98)Address already in use: make_sock: could not bind to address [::]:80
    (98)Address already in use: make_sock: could not bind to address 0.0.0.0:80
    no listening sockets available, shutting down
    Unable to open logs
    [FAILED]
&lt;/code&gt;&lt;/pre&gt;
&lt;/br&gt;
&lt;h2 id=&quot;2-netstat&quot;&gt;2. &lt;em&gt;netstat&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;The netstat command shows the services listening to ports on a Linux server along with the details of any connections currently made to them. The connection details we look at during basic network daemon troubleshooting are the addresses the daemon is listening on (including the port number), the daemon's PID (process identifier), and the program name.&lt;/p&gt;
&lt;h3 id=&quot;a-list-service-and-their-open-ports&quot;&gt;A. List service and their open ports&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;~$ netstat -tulpn
    Active Internet connections (only servers)
    Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
    tcp        0      0 127.0.0.1:58789         0.0.0.0:*               LISTEN      10371/current
    tcp        0      0 127.0.0.1:50149         0.0.0.0:*               LISTEN      9039/current
    tcp        0      0 127.0.0.1:11110         0.0.0.0:*               LISTEN      29248/fmsadmin
    tcp        0      0 0.0.0.0:8134            0.0.0.0:*               LISTEN      29086/httpd
&lt;/code&gt;&lt;/pre&gt;
&lt;/br&gt;
&lt;h2 id=&quot;3-ps-commands-show-running-processes-in-ubuntu&quot;&gt;3. &lt;em&gt;ps&lt;/em&gt; commands Show Running Processes in Ubuntu&lt;/h2&gt;
&lt;p&gt;It provides information about the currently running processes, including their process identification numbers (PIDs). &lt;/p&gt;
&lt;h3 id=&quot;a-to-display-all-running-processes&quot;&gt;A. To display all running processes:&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;~$ ps aux

    USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
    mysql     5801  0.0  1.1 1366504 48444 ?       Ssl  Aug05  12:27 /usr/sbin/mysql
    root     10232  0.0  0.3 315796 13012 ?        Ss   Sep03   0:01 /usr/sbin/apach
    www-data 10247  0.0  0.9 346356 40620 ?        S    Sep03   0:00 /usr/sbin/apach
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where,&lt;/p&gt;
&lt;blockquote&gt;
    &lt;ul&gt;
        &lt;li&gt;-A: select all processes&lt;/li&gt;
        &lt;li&gt;a: select all processes on a terminal, including those of other users&lt;/li&gt;
        &lt;li&gt;x: select processes without controlling ttys&lt;/li&gt;
    &lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;b-to-display-all-apache-2-processes&quot;&gt;B. To display all apache 2 processes:&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;~$ ps aux | grep apache2
    root     10232  0.0  0.3 315796 13012 ?        Ss   Sep03   0:01 /usr/sbin/apache2 -k start
    www-data 10247  0.0  0.9 346356 40620 ?        S    Sep03   0:00 /usr/sbin/apache2 -k start
    www-data 19768  0.0  0.2 317048 10016 ?        S    02:35   0:00 /usr/sbin/apache2 -k start
    www-data 19770  0.0  1.4 585788 59992 ?        S    02:35   0:00 /usr/sbin/apache2 -k start
    www-data 19812  0.0  0.1 315964  7676 ?        S    02:36   0:00 /usr/sbin/apache2 -k start
    www-data 20100  0.0  0.1 315964  7676 ?        S    03:02   0:00 /usr/sbin/apache2 -k start
    root     20356  0.0  0.0   6460   820 pts/2    S+   03:20   0:00 grep --color=auto apache2
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;c-to-see-all-the-processes-on-system-with-their-pids&quot;&gt;C. To see all the processes on system with their pids&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;~$ ps -e
    PID TTY          TIME CMD
    1 ?        00:00:29 init
    2 ?        00:00:00 kthreadd/104
    3 ?        00:00:00 khelper/104
    68 ?        00:00:00 upstart-udev-br
    78 ?        00:00:00 udevd
    99 ?        00:00:00 dbus-daemon
    119 ?        00:00:00 udevd
    121 ?        00:00:00 udevd
    191 ?        00:00:05 cron
    200 ?        00:00:00 upstart-socket-
    242 ?        00:00:20 syslogd
    374 ?        00:00:00 saslauthd
    375 ?        00:00:00 saslauthd
    536 ?        00:00:00 xinetd
    561 ?        00:01:31 sendmail-mta
    5801 ?        00:12:27 mysqld
    10232 ?        00:00:01 apache2
    10247 ?        00:00:00 apache2
    18760 ?        03:28:46 mongod
    19768 ?        00:00:00 apache2
    19770 ?        00:00:00 apache2
    19812 ?        00:00:00 apache2
    20100 ?        00:00:00 apache2
    20176 ?        00:00:00 sshd
    20198 ?        00:00:00 sshd
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;d-to-view-the-processes-running-by-a-particular-user-for-eg-vivek&quot;&gt;D. To view the processes running by a particular user for e.g vivek&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;~$ ps -u vivek
    PID TTY          TIME CMD
    20198 ?        00:00:00 sshd
    20199 pts/2    00:00:00 sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;e-to-see-dynamic-real-time-view-of-a-running-system&quot;&gt;E. To see dynamic real-time view of a running system&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;~$ top
    top - 03:25:52 up 29 days, 18:15,  2 users,  load average: 0.02, 0.01, 0.00
    Tasks:  35 total,   1 running,  34 sleeping,   0 stopped,   0 zombie
    Cpu(s):  0.0%us,  0.0%sy,  0.0%ni,100.0%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
    Mem:   4194304k total,   694824k used,  3499480k free,        0k buffers
    Swap:  4194304k total,    47984k used,  4146320k free,   555992k cached

    PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
    5801 mysql     20   0 1334m  47m 4408 S    0  1.2  12:27.46 mysqld
    18760 mongodb   20   0  639m 1708 1348 S    0  0.0 208:47.00 mongod
    121 root      20   0 21524  448  284 S    0  0.0   0:00.00 udevd
    191 root      20   0 19068  832  752 S    0  0.0   0:05.36 cron
    20176 root      20   0  127m 4984 3848 S    0  0.1   0:00.03 sshd
    20198 vivek     20   0  127m 1992  840 S    0  0.0   0:00.01 sshd
    20199 vivek     20   0  4356  712  596 S    0  0.0   0:00.00 sh
    20300 root      20   0  127m 4996 3860 S    0  0.1   0:00.03 sshd
    20323 nishant   20   0  127m 1952  824 S    0  0.0   0:00.06 sshd
    20324 nishant   20   0  9800 1888 1440 S    0  0.0   0:00.02 bash
    20431 www-data  20   0  308m 7804  884 S    0  0.2   0:00.00 apache2
    20443 root      20   0  8944 1188  956 R    0  0.0   0:00.00 top
    20444 nslcd     20   0  449m 2092 1068 S    0  0.0   0:03.71 nslcd
    20549 root      20   0 1140m 1644 1012 S    0  0.0   0:26.11 nscd
    20792 root      20   0  195m 8084 2072 S    0  0.2   8:18.36 fail2ban-server
    20794 root      20   0 22484 1396 1072 S    0  0.0   0:13.57 gam_server
    22233 root      20   0 50436 2892 2304 S    0  0.1   0:00.29 sshd
    24603 root      20   0  7220 1052  544 S    0  0.0   0:19.43 dhclient
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;NOTE:
    &lt;em&gt; To quit press &lt;/em&gt;q&lt;em&gt;
    &lt;/em&gt; In order to sort by a memory usage hit shift + m and the screen will show highest descending memory usage
    &lt;em&gt; For help press &lt;/em&gt;h*&lt;/p&gt;
&lt;/br&gt;
&lt;h2 id=&quot;4-get-cpu-system-load-average-on-ubuntu&quot;&gt;4. Get CPU / System Load Average on Ubuntu&lt;/h2&gt;
&lt;p&gt;What we might need to know is the overall system load on a server.
    There are a couple of ways to get this information, which may or may not be enabled on your system. It’s useful to know more than one way to get the uptime information in case the commands are disabled on your shared hosting server.&lt;/p&gt;
&lt;h3 id=&quot;a-uptime&quot;&gt;A. uptime&lt;/h3&gt;
&lt;p&gt;This command gives information on system load averages for the past 1, 5, and 15 minutes:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~$ uptime
    03:32:28 up 29 days, 18:21,  2 users,  load average: 0.07, 0.05, 0.02
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Higher numbers &lt;em&gt;load average: 0.07, 0.05, 0.02&lt;/em&gt; represent a problem or an overloaded machine. But, what's the the threshold? What constitutes &quot;good&quot; and &quot;bad&quot; load average values? When should you be concerned over a load average value, and when should you scramble to fix it ASAP?&lt;/p&gt;
&lt;h4 id=&quot;the-traffic-analogy&quot;&gt;The traffic analogy&lt;/h4&gt;
&lt;p&gt;A single-core CPU is like a single lane of traffic with one toll. Imagine you are a toll operator ... sometimes your toll is so busy there are cars lined up to cross. So the question is what are the metrics which tells how much busy or crowded toll is ? Its simple how many cars are in waiting at particular interval of time to cross the toll. If their is huge backlog of cars then it means traffic is high and causing congestions.&lt;/p&gt;
&lt;p&gt;So in our context we use different numbering system to understand the traffic congestion on particular toll like :&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;&lt;em&gt;0.00 means there's no traffic on the bridge at all&lt;/em&gt;. In fact, between 0.00 and 1.00 means there's no backup, and an arriving car will just go right on.&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;1.00 means the bridge is exactly at capacity&lt;/em&gt;. All is still good, but if traffic gets a little heavier, things are going to slow down.&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;over 1.00 means there's backlog&lt;/em&gt;. How much? Well, 2.00 means that there are two lanes worth of cars total -- one lane's worth on the toll, and one lane's worth waiting. 3.00 means there are three lane's worth total -- one lane's worth on the toll, and two lanes' worth waiting. Etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;so-from-above-explanaiton-the-ideal-load-is-100&quot;&gt;So from above explanaiton the ideal load is 1.00?&lt;/h4&gt;
&lt;p&gt;Well, not exactly.&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;
        &lt;p&gt;The &lt;em&gt;Need to Look into it&lt;/em&gt; Rule of Thumb: &quot;0.70&quot; If your load average is staying above &amp;gt; 0.70, it's time to investigate before things get worse.&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
        &lt;p&gt;The &lt;em&gt;Fix this now&lt;/em&gt; Rule of Thumb: &lt;em&gt;1.00&lt;/em&gt;. If your load average stays above 1.00, find the problem and fix it now. Otherwise, you're going to get woken up in the middle of the night, and it's not going to be fun.&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
        &lt;p&gt;The &lt;em&gt;Arrgh, it's 3AM WTF?&lt;/em&gt; Rule of Thumb: 5.0. If your load average is above 5.00, you could be in serious trouble, your box is either hanging or slowing way down, and this will (inexplicably) happen in the worst possible time like in the middle of the night or when you're presenting at a conference. Don't let it get there.&lt;/p&gt;
    &lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;now-the-good-question-is-what-about-multi-processors&quot;&gt;Now the good question is what about Multi-processors?&lt;/h4&gt;
&lt;p&gt;On multi-processor system, the load is relative to the number of processor cores available. The &quot;100% utilization&quot; mark is 1.00 on a single-core system, 2.00, on a dual-core, 4.00 on a quad-core, etc. This lead us to a 2 new Rules of Thumb:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;
        &lt;p&gt;The &lt;em&gt;number of cores = max load&lt;/em&gt; Rule of Thumb: on a multicore system, your load should not exceed the number of cores available.&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
        &lt;p&gt;The &lt;em&gt;cores is cores&lt;/em&gt; Rule of Thumb: How the cores are spread out over CPUs doesn't matter. Two quad-cores == four dual-cores == eight single-cores. It's all eight cores for these purposes.&lt;/p&gt;
    &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So # of cores is important to interpreting load averages ... how do we know how many cores present in our system?&lt;/p&gt;
&lt;h3 id=&quot;b-to-get-info-on-each-processor-in-your-system&quot;&gt;B. To get info on each processor in your system.&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;~$ cat /proc/cpuinfo
    processor : 0
    vendor_id    : GenuineIntel
    cpu family  : 6
    model       : 44
    model name  : Intel(R) Xeon(R) CPU           E5645  @ 2.40GHz
    stepping    : 2
    microcode   : 0x10
    cpu MHz     : 1999.975
    cache size  : 12288 KB
    physical id : 0
    siblings    : 1
    core id     : 0
    cpu cores   : 1
    apicid      : 0
    initial apicid  : 52
    fpu     : yes
    fpu_exception   : yes
    cpuid level : 11
    wp      : yes
    flags       : fpu de tsc msr pae cx8 sep cmov pat clflush mmx fxsr sse sse2 ss ht syscall nx lm constant_tsc up rep_good nopl nonstop_tsc pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 popcnt aes hypervisor lahf_lm
    bogomips    : 3999.95
    clflush size    : 64
    cache_alignment : 64
    address sizes   : 40 bits physical, 48 bits virtual
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;c-to-get-just-a-count-do-grep-and-word-count&quot;&gt;C. To get just a count do grep and word count:.&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;~$ grep 'model name' /proc/cpuinfo | wc -l
    1 =&amp;gt; Number of cpu is one
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Setting Up Rails App Using Unicorn With Nginx For Zero Downtime Deployment</title>
   <link href="http://vparihar01.github.io/setup/2013/07/21/setting-up-rails-app-using-unicorn-with-nginx-for-zero-downtime-deployment"/>
   <updated>2013-07-21T00:00:00+05:30</updated>
   <id>http://vparihar01.github.io/setup/2013/07/21/setting-up-rails-app-using-unicorn-with-nginx-for-zero-downtime-deployment</id>
   <content type="html">
&lt;p&gt;Unicorn is a traditional UNIX(which makes great use of Unix) prefork web server.No threads are used at all, this makes applications easier to debug and fix.&lt;/p&gt;
&lt;h2 id=&quot;deploying&quot;&gt;Deploying&lt;/h2&gt;
&lt;p&gt;With Unicorn one can deploy with zero downtime. From Unicorn documetation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You can upgrade Unicorn, your entire application, libraries and even your Ruby interpreter without dropping clients.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;rails-on-unicorns&quot;&gt;Rails on Unicorns&lt;/h2&gt;
&lt;p&gt;Now we start setting up rails using ngnix with unicorn.&lt;/p&gt;
&lt;h3 id=&quot;installing-nginx&quot;&gt;Installing Nginx&lt;/h3&gt;
&lt;p&gt;To install Nginx web server on our ubuntu server:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt-get install nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;We could start the server with the nginx command but the installer also installs an init.d file that we can use to manage our nginx server as well.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;$ /etc/init.d/nginx -h
Usage: nginx {start|stop|restart|reload|force-reload|status|configtest}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can run this&lt;code&gt;init.d&lt;/code&gt; command directly or we can interact with it through the service command and we'll use this to start it up.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo service nginx start
Starting nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
configuration file /etc/nginx/nginx.conf test is successful nginx.
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;configuring-nginx-to-run-on-a-port-80&quot;&gt;Configuring nginx to run on a port =&amp;gt; 80&lt;/h3&gt;
&lt;p&gt;All main configuration file reside at &lt;code&gt;/etc/nginx/nginx.conf&lt;/code&gt; and by default it looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat /etc/nginx/nginx.conf
user nobody nogroup; # for systems with a &amp;quot;nogroup&amp;quot;
worker_processes  1;

error_log  /var/log/nginx/error.log;
pid        /var/run/nginx.pid;

events {
    worker_connections  1024;
    # multi_accept on;
}

http {
    include       /etc/nginx/mime.types;

    access_log        /var/log/nginx/access.log;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;
    tcp_nodelay        on;

    gzip  on;
    gzip_disable &amp;quot;MSIE [1-6]\.(?!.*SV1)&amp;quot;;

    include /etc/nginx/conf.d/*.conf;
    include /etc/nginx/sites-enabled/*;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In &lt;code&gt;nginx.conf&lt;/code&gt; you may have stumbled upon this line:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;user nobody nogroup; # for systems with a &quot;nogroup&quot;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Its generally adviced to run as a seperate user for security reasons and increased control. Weâ€™ll create an nginx user and a web group.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo useradd -s /sbin/nologin -r deploy
$ sudo usermod -a -G deploy deploy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Configure your static path in &lt;code&gt;nginx.conf&lt;/code&gt; to &lt;code&gt;/var/www&lt;/code&gt;, and change the owner of that directory to the web group:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo mkdir /var/www
$ sudo chgrp -R deploy /var/www # set /var/www owner group to &amp;quot;deploy&amp;quot;
$ sudo chmod -R 775 /var/www # group write permission
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;To avoid permission issues we're going to make Nginx run as a deployer, the user that's going to deploy the application code, this way we can rest safely that no â€œpermission deniedâ€ on files will ever happen (at least as long as we donâ€™t deploy as another user).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now change this default &lt;code&gt;nginx.conf&lt;/code&gt; file like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;user  deploy deploy; 
worker_processes  1;
worker_priority  -5;
timer_resolution  100ms;

error_log  /var/log/nginx/error.log;

# To enable to open as many files as possible within a single nginx worker process without crashing increase default 1024 value to some higher value
worker_rlimit_nofile 30240;

events {
    use  epoll;
    worker_connections  10240;
}

http {
    client_header_buffer_size 1460;
    client_body_timeout  1460;
    client_max_body_size      25m;
    client_body_buffer_size   128k;
    client_body_temp_path     /tmp/client_body_temp;
    large_client_header_buffers 8 8m; 

    include                   mime.types;
    default_type              application/octet-stream;
    keepalive_timeout         1300;

    gzip                      on;
    gzip_http_version         1.1;
    gzip_disable              &amp;quot;msie6&amp;quot;;
    gzip_vary                 on;
    gzip_min_length           500; #Compress everything no matter the size
    gzip_buffers              64 8k;
    gzip_comp_level           3;
    gzip_proxied              any;
    gzip_types                text/plain text/css application/x-javascript text/xml application/xml;

    proxy_connect_timeout  300;
    proxy_send_timeout  300;
    proxy_read_timeout  300;
    proxy_buffering on;
    proxy_buffers 8 16k;
    proxy_buffer_size 32k;

    # For better performance we use Linux sendfile():
    sendfile       on;

    # To send all response headers in one packet. This allows a client to start rendering content immediately after the first packet arrives:
    tcp_nopush     on;
    tcp_nodelay    off;

    log_format  main  '$remote_addr - $remote_user [$time_local] &amp;quot;$request&amp;quot; '
                      '$status $body_bytes_sent &amp;quot;$http_referer&amp;quot; '
                      '&amp;quot;$http_user_agent&amp;quot; &amp;quot;$http_x_forwarded_for&amp;quot;';

    include /etc/nginx/conf.d/*.conf;
    include /etc/nginx/sites-enabled/*;

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To run a single application in this server, we can go on and edit the &lt;code&gt;/etc/nginx/sites-available/default&lt;/code&gt; file directly, if you are going to host more than one application in this server you should create separate files for each of them and then symlink them to the &lt;code&gt;/etc/nginx/sites-enabled/&lt;/code&gt; folder.&lt;/p&gt;
&lt;p&gt;Add a new file &lt;code&gt;unicorn_rails_app.conf&lt;/code&gt; in the site-available directory and copy and paste the following into it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;upstream unicorn_rails_app {
    # fail_timeout=0 means we always retry an upstream even if it failed
    # to return a good HTTP response (in case the Unicorn master nukes a
    # single worker for timing out).

    # for UNIX domain socket setups:
  server unix:/var/www/rails_app/current/tmp/unicorn.rails_app.sock fail_timeout=0;
}

server {
  # if you're running multiple servers, instead of &amp;quot;default&amp;quot; you should
  # put your main domain name here
  listen 80 default;

  # you could put a list of other domain names this application answers
  server_name your.domain_name.com;

  # path for static files
  root /var/www/rails_app/current/public;
  access_log /var/log/nginx/rails_app_access.log;

  location / {
    proxy_pass http://unicorn_rails_app;            
    proxy_redirect     off;

    proxy_set_header   Host             $host:$proxy_port;
    proxy_set_header   X-Real-IP        $remote_addr;
    client_max_body_size 4m;
  #  proxy_ignore_client_abort on;
  }
  # if the request is for a static resource, nginx should serve it directly
  # and add a far future expires header to it, making the browser
  # cache the resource and navigate faster over the website
  location ~ ^/(images|javascripts|stylesheets|system)/  {
     root /var/www/rails_app/current/public;
     add_header Last-Modified &amp;quot;&amp;quot;;
     add_header ETag &amp;quot;&amp;quot;;
     expires max;
     break;
  }
  # Rails error pages
  error_page 500 502 503 504 /500.html;
  location = /500.html {
    root /path/to/app/current/public;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After creating this new file &lt;code&gt;unicorn_rails_app.conf&lt;/code&gt;, we need to symlink it to the sites-enabled directory:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo ln -s /etc/nginx/sites-available/unicorn_rails_app.conf /etc/nginx/sites-enabled/unicorn_rails_app.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;unicorn-setup&quot;&gt;Unicorn setup&lt;/h3&gt;
&lt;p&gt;Now we have nginx running. Install the Unicorn gem:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gem install unicorn
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add the unicorn gem to your Rails application's Gemfile&lt;/p&gt;
&lt;h4 id=&quot;gemfile&quot;&gt;Gemfile&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;source 'https://rubygems.org'&lt;/p&gt;
&lt;p&gt;gem 'rails', '3.2.12'&lt;/p&gt;
&lt;p&gt;gem 'unicorn'&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;create-the-unicorn-configuration-file-in-your-rails-application-configunicornrb-copy-the-below-lines&quot;&gt;Create the Unicorn configuration file in your Rails application &lt;code&gt;config/unicorn.rb&lt;/code&gt; (copy the below lines):&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;$ vim config/unicorn.rb

# Unicorn configuration file to be running by unicorn_init.sh with capistrano task
# read an example configuration before: http://unicorn.bogomips.org/examples/unicorn.conf.rb
# 
# working_directory, pid, paths - internal Unicorn variables must to setup
# worker_process 4              - is good enough for serve small production application
# timeout 30                    - time limit when unresponded workers to restart
# preload_app true              - the most interesting option that confuse a lot of us,
#                                 just setup is as true always, it means extra work on 
#                                 deployment scripts to make it correctly
# BUNDLE_GEMFILE                - make Gemfile accessible with new master
# before_fork, after_fork       - reconnect to all dependent services: DB, Redis, Sphinx etc.
#                                 deal with old_pid only if CPU or RAM are limited enough
#
# config/server/production/unicorn.rb

app_path          = &amp;quot;/var/www/rails_app/current&amp;quot;

working_directory &amp;quot;#{app_path}&amp;quot;
pid               &amp;quot;#{app_path}/tmp/pids/unicorn.pid&amp;quot;
stderr_path       &amp;quot;#{app_path}/log/unicorn.log&amp;quot;
stdout_path       &amp;quot;#{app_path}/log/unicorn.log&amp;quot;

listen            &amp;quot;#{app_path}/tmp/unicorn.rails_app.sock&amp;quot; , :backlog =&amp;gt; 64

user 'deploy','deploy'
#listen 80, :tcp_nopush =&amp;gt; true 
#listen 8080, :tcp_nopush =&amp;gt; true
worker_processes  4
timeout           600
preload_app       true
GC.respond_to?(:copy_on_write_friendly=) and
  GC.copy_on_write_friendly = true
before_fork do |server, worker|
  # the following is highly recomended for Rails + &amp;quot;preload_app true&amp;quot;
  # as there's no need for the master process to hold a connection
  defined?(ActiveRecord::Base) and
    ActiveRecord::Base.connection.disconnect!
end

after_fork do |server, worker|
  # per-process listener ports for debugging/admin/migrations
  # addr = &amp;quot;127.0.0.1:#{9293 + worker.nr}&amp;quot;
  # server.listen(addr, :tries =&amp;gt; -1, :delay =&amp;gt; 5, :tcp_nopush =&amp;gt; true)

  # the following is *required* for Rails + &amp;quot;preload_app true&amp;quot;,
  defined?(ActiveRecord::Base) and
    ActiveRecord::Base.establish_connection

  # if preload_app is true, then you may also want to check and
  # restart any other shared sockets/descriptors such as Memcached,
  # and Redis.  TokyoCabinet file handles are safe to reuse
  # between any number of forked children (assuming your kernel
  # correctly implements pread()/pwrite() system calls)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Then Unicorn is configured!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;create-a-unicorn-initializer-shell-script-in-the-varwwwrails_appcurrentconfig-directory-to-startstoprestart-unicorn-processes&quot;&gt;Create a Unicorn initializer shell script in the &lt;code&gt;/var/www/rails_app/current/config&lt;/code&gt; directory to start|stop|restart unicorn processes:&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;$ touch /var/www/rails_app/current/config/unicorn

$ vim /var/www/rails_app/current/config/unicorn
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;paste-the-following-into-that-new-file&quot;&gt;Paste the following into that new file:&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;#! /bin/bash

### BEGIN INIT INFO
# Provides:          unicorn
# Required-Start:    $local_fs $remote_fs $network $syslog
# Required-Stop:     $local_fs $remote_fs $network $syslog
# Default-Start:     2 3 4 5
# Default-Stop:      0 1 6
# Short-Description: starts the unicorn web server
# Description:       starts unicorn
### END INIT INFO

APP_ROOT=&amp;quot;/var/www/rails_app&amp;quot;
USER=&amp;quot;deploy&amp;quot;
DAEMON=unicorn_rails
DAEMON_OPTS=&amp;quot;-c $APP_ROOT/shared/config/unicorn.rb -E staging -D&amp;quot;
NAME=unicorn
DESC=&amp;quot;Unicorn app for $USER&amp;quot;
PID=$APP_ROOT/shared/pids/unicorn.pid

case &amp;quot;$1&amp;quot; in
  start)
        CD_TO_APP_DIR=&amp;quot;cd $APP_ROOT&amp;quot;
        START_DAEMON_PROCESS=&amp;quot;bundle exec $DAEMON $DAEMON_OPTS&amp;quot;

        echo -n &amp;quot;Starting $DESC: &amp;quot;
        if [ `whoami` = root ]; then
          su - $USER -c &amp;quot;$CD_TO_APP_DIR &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;&amp;amp; $START_DAEMON_PROCESS&amp;quot;
        else
          $CD_TO_APP_DIR &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;&amp;amp; $START_DAEMON_PROCESS
        fi
        echo &amp;quot;$NAME.&amp;quot;
        ;;
  stop)
        echo -n &amp;quot;Stopping $DESC: &amp;quot;
        kill -QUIT `cat $PID`
        echo &amp;quot;$NAME.&amp;quot;
        ;;
  restart)
        echo -n &amp;quot;Restarting $DESC: &amp;quot;
        kill -USR2 `cat $PID`
        echo &amp;quot;$NAME.&amp;quot;
        ;;
  reload)
        echo -n &amp;quot;Reloading $DESC configuration: &amp;quot;
        kill -HUP `cat $PID`
        echo &amp;quot;$NAME.&amp;quot;
        ;;
  *)
        echo &amp;quot;Usage: $NAME {start|stop|restart|reload}&amp;quot; &amp;gt;&amp;amp;2
        exit 1
        ;;
esac

exit 0
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;start-nginx-server&quot;&gt;Start nginx server&lt;/h4&gt;
&lt;p&gt;Start your nginx server from its installation directory:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ /etc/init.d/nginx restart
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;start-unicorn-server&quot;&gt;Start Unicorn server&lt;/h4&gt;
&lt;p&gt;Start your Unicorn server from your Rails application directory, with no port specified (it will use the Unix socket from its configuration instead):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ unicorn_rails -E production -D -c /var/www/rails_app/current/config/unicorn.rb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Voila here's your chocolate.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>A Reflection On Ruby Conf India 2013</title>
   <link href="http://vparihar01.github.io/talks/2013/06/22/A-reflection-on-Ruby-Conf-India-2013"/>
   <updated>2013-06-22T00:00:00+05:30</updated>
   <id>http://vparihar01.github.io/talks/2013/06/22/A-reflection-on-Ruby-Conf-India-2013</id>
   <content type="html">&lt;img alt='Webonise sponsoring Ruby Conf India 2013' src='/assets/themes/twitter/bootstrap/img/186.png' style='float: right' /&gt;
&lt;p&gt;This year was Ruby Conf India was conducted in Pune(good for me, i live in Pune itself;) ) Our company – &lt;strong&gt;Weboniselab&lt;/strong&gt; bagged the &lt;strong&gt;silver sponsorship&lt;/strong&gt; for the Ruby Conf India 2013. Being my third time at the conference, i felt like a regular, my excitement nevertheless same as a first timer.&lt;/p&gt;

&lt;p&gt;At the conference, I did not experience much difference from the previous ones that i attended. Although, what I liked the most in this edition was the increased community size and growing involvement of Rubyists. This year we saw a great deal of people attending the conference and the rise in the number was substantial this year. Also, what i found interesting was the increased number of women participation. Its always nice to see the Ruby community grow to become strong and healthy.&lt;/p&gt;

&lt;p&gt;Talking about the sessions and especially my favourite ones!&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Aaron Patterson&lt;/strong&gt;,&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Richard Schneeman&lt;/strong&gt;,&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Jim Weirich&lt;/strong&gt; and&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Jonathan Wallace&lt;/strong&gt; gave truely inspirational talks.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id='talks'&gt;Talks&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Aaron Patterson&lt;/strong&gt; spoke on &lt;strong&gt;&amp;#8220;Keynote on Rails and open source contribution&amp;#8221;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;He provided some insight on the new features in the upcoming Rails 4. He also spoke about his experience as an Open Source Software developer, what he needed to become one and shared how it felt when people benefit from your contribution. He also talked about ways for developing ourselves and also provided lots of health tips :)&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Jonathan spoke on &amp;#8220;Effective Debugging&amp;#8221;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;His method of effective debugging gave a clear understanding on how we can effectively debug someone else&amp;#8217;s application , while collaborating with others on their project. Jonathan showed lots of tricks which could give any individual a thorough understanding of the third party application. Developers are always looking for ways to boost productivity during development and being able to effectively debug the application becomes a crucial part to achieve optimum productivity with less code. He effectively conveyed how debugging allows one to easily discover inaccuracies between our expectations and how the software actually behaves.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Richard Schneeman spoke on &amp;#8220;techniques of dissecting Ruby with Ruby&amp;#8221;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;As for me, I learnt how to use simple and sharp Ruby tools to slice into large libraries with surgical precision. Schneeman gave a live demonstration by hacking into Rails showing useful code probing techniques. This talk turned me from a bug reporter to bug fixer!&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Jim Weirich&amp;#8217;s talk on &amp;#8220;Test cases and TDD approach - Kata and Analysis&amp;#8221;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;He built a roman calculator using the TTD approach.His approach towards understanding how to develop applications through TDD was refreshingly interesting.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id='atmoshphere_in_conference_'&gt;Atmoshphere in conference :)&lt;/h2&gt;

&lt;p&gt;Moving on to the atmosphere and the vibe of the conference, communication among the participants in the conference and speakers felt smooth and good. I had the opportunity to meet lots of new people and discuss the latest trends that they are implementing in their work culture and there was a healthy communication among us and other participants. All the people i met are wonderful and they generously share their knowledge and experiences.&lt;/p&gt;

&lt;h2 id='lesson_learned'&gt;Lesson Learned!!&lt;/h2&gt;

&lt;p&gt;The lesson i came home with was the importance of &lt;em&gt;Open Source Contribution&lt;/em&gt;, giving back and contributing to the community and growing with it as a developer. I am, personally, actively involved in open source contribution to the ruby community. I felt proud when i heard people mention my work, in our discussion, had helped a lot of people and his appreciation meant a lot to me. It feels good to know that you are able to give back something to the community in return and even better when its appreciated by such renowned people.&lt;/p&gt;

&lt;h2 id='realisation'&gt;Realisation&lt;/h2&gt;

&lt;p&gt;What i realised, is that its not always about contributing to benefit an entire community, but about making that contribution even if its towards an individual&amp;#8217;s benefit or towards a smaller organisation in your own small way. The general vibe sent out through Ruby Conf India 2013 was to take the community by the hand and grow as rubyists along with the others.&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Humongous Db Back To Documents</title>
   <link href="http://vparihar01.github.io/talks/2013/04/05/HuMongous-Db-Back-to-Documents"/>
   <updated>2013-04-05T00:00:00+05:30</updated>
   <id>http://vparihar01.github.io/talks/2013/04/05/HuMongous-Db-Back-to-Documents</id>
   <content type="html">

&lt;p&gt;Below is the presentation on MongoDb basic which is given by me, it is short and covered a lot of enlightened point which is really helpful for the people who are novice in MongoBb. Here we not only discuss the importance of MongoBb, but also a different scenario where SQL and No SQL (i.e No Only SQL) is good and each one possess their own importance. Also some info about 10Gen's support for MongoBb users.&lt;/p&gt;
&lt;!--&lt;iframe src=&quot;http://www.slideshare.net/slideshow/embed_code/24686234&quot; width=&quot;425&quot; height=&quot;355&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot; allowfullscreen&gt;&lt;/iframe&gt;--&gt;
&lt;iframe src=&quot;http://www.slideshare.net/slideshow/embed_code/24686234&quot; width=&quot;427&quot; height=&quot;356&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot; style=&quot;border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px&quot; allowfullscreen webkitallowfullscreen mozallowfullscreen&gt; &lt;/iframe&gt; &lt;div style=&quot;margin-bottom:5px&quot;&gt; &lt;strong&gt; &lt;a href=&quot;http://www.slideshare.net/vivekparihar1/hu-mongous-db-v2&quot; title=&quot;Hu mongous db v2&quot; target=&quot;_blank&quot;&gt;Hu mongous db v2&lt;/a&gt; &lt;/strong&gt; from &lt;strong&gt;&lt;a href=&quot;http://www.slideshare.net/vivekparihar1&quot; target=&quot;_blank&quot;&gt;Vivek Parihar&lt;/a&gt;&lt;/strong&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Multiple Ssh Keys Settings For Different Github Account</title>
   <link href="http://vparihar01.github.io/setup/2013/04/03/multiple-ssh-keys-settings-for-different-github-account"/>
   <updated>2013-04-03T00:00:00+05:30</updated>
   <id>http://vparihar01.github.io/setup/2013/04/03/multiple-ssh-keys-settings-for-different-github-account</id>
   <content type="html">
&lt;p&gt;Github using SSH client connection. If it is a single-user (first), generate a key pair, the public key saved to github, each time you connect the SSH client sends the local private key (the default &lt;em&gt;~~/.ssh/id_rsa&lt;/em&gt;) to the server authentication. In the case of single-user public key SSH client send the private key stored on the server connection is naturally paired. But if it is multi-user (first, second), we connected to the second account, the second to save the public key, but SSH client still send the default private key, that is, the first private key, then verify that naturally can not through. However, to achieve multiple accounts under the SSH key to switch on the client to do some configuration can be.&lt;/p&gt;
&lt;h2 id=&quot;step-1-go-to-ssh-key-dir&quot;&gt;Step 1: Go to SSH key dir&lt;/h2&gt;
&lt;p&gt;First, cd to &lt;strong&gt;~/ssh&lt;/strong&gt; to use &lt;strong&gt;ssh-keygen -t rsa -C 'your_mail@youremail.com'&lt;/strong&gt; to generate new SSH key
You are then prompted for an optional password. After the key is generate you copy &amp;amp; paste it into your GitHub account settings.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Create different public key&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;step-2-generate-a-first-ssh-key&quot;&gt;Step 2: Generate a First SSH key&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Create first user with&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ssh-keygen -t rsa -C &amp;quot;email@domain.com&amp;quot;
# Creates a new ssh key, using the provided email as a label
# Generating public/private rsa key pair.
# Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which should give you something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Your identification has been saved in /Users/you/.ssh/id_rsa.
# Your public key has been saved in /Users/you/.ssh/id_rsa.pub.
# The key fingerprint is:
# 01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db email@domain.com
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You are then prompted for an optional password. After the key is generate you copy &amp;amp; paste it into your GitHub account settings.&lt;/p&gt;
&lt;h2 id=&quot;step-3-generate-a-second-ssh-key&quot;&gt;Step 3: Generate a Second SSH key&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Create second user with&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ssh-keygen -t rsa -f ~/.ssh/second_rsa -C &amp;quot;email@domain.com&amp;quot;
# Creates a new ssh key, using the provided email as a label
# Generating public/private rsa key pair.
# Enter file in which to save the key (/Users/you/.ssh/second_rsa): [Press enter]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which should give you something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Your identification has been saved in /Users/you/.ssh/second_rsa.
# Your public key has been saved in /Users/you/.ssh/second_rsa.pub.
# The key fingerprint is:
# 01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db email@domain.com
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;step-4-add-saved-ssk-keys&quot;&gt;Step 4: Add Saved SSK keys&lt;/h2&gt;
&lt;p&gt;After Step 3: two SSH keys created at &lt;strong&gt;~/.ssh&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~/.ssh/id_rsa
~/.ssh/second_rsa
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, add these two keys as following&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ssh-add ~/.ssh/id_rsa
$ ssh-add ~/.ssh/second_rsa
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can delete all cached keys before&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ssh-add -D
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;step-5-finally-you-can-check-your-saved-keys&quot;&gt;Step 5: Finally, you can check your saved keys&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;$ ssh-add -l
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;step-6-modify-the-ssh-config&quot;&gt;Step 6: Modify the ssh config&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;$ cd ~/.ssh/
$ touch config
$ subl -a config
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then add below lines into &lt;strong&gt;config&lt;/strong&gt; file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#First account
Host github.com
  HostName github.com
  User git
  IdentityFile ~/.ssh/id_rsa

#Second account
Host github.com-second
  HostName github.com
  User git
  IdentityFile ~/.ssh/second_rsa
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;step-7-test-everything-out&quot;&gt;Step 7: Test everything out&lt;/h2&gt;
&lt;p&gt;To make sure everything is working you'll now SSH to GitHub. When you do this, you will be asked to authenticate this action using your password, which for this purpose is the passphrase you created earlier. Don't change the git@github.com part. That's supposed to be there.&lt;br /&gt;
&lt;em&gt;For first SSH key do this&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ssh -T git@github.com
# Attempts to ssh to github using first ssh key
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;You may see this warning&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# The authenticity of host 'github.com (207.97.227.239)' can't be established.
# RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.
# Are you sure you want to continue connecting (yes/no)?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Don't worry, this is supposed to happen. Verify that the fingerprint matches the one here and type &lt;strong&gt;yes&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Hi username! You've successfully authenticated, but GitHub does not
# provide shell access.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;For Second SSH key do this&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ssh -T git@github.com-second
# Attempts to ssh to github using second ssh key
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;You may see this warning&lt;/em&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# The authenticity of host 'github.com (207.97.227.239)' can't be established.
# RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.
# Are you sure you want to continue connecting (yes/no)?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Don't worry, this is supposed to happen. Verify that the fingerprint matches the one here and type &lt;strong&gt;yes&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Hi username! You've successfully authenticated, but GitHub does not
# provide shell access.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;step-8-clone-your-repo-and-modify-your-git-config&quot;&gt;Step 8: Clone your repo and modify your Git config&lt;/h2&gt;
&lt;p&gt;With this set up I can clone with my default key as Github suggests:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Clone your repo&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git clone git@github.com:username/project.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If I want to clone a repository from my second account I can alter the command to use the second SSH key I generated:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Clone your repo&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git clone git@github.com-second:username/project.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cd project and modify git config&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git config user.name &amp;quot;First User&amp;quot;
$ git config user.email &amp;quot;first_email@email.com&amp;quot;

$ git config user.name &amp;quot;Second User&amp;quot;
$ git config user.email &amp;quot;second_email@mail.com&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or you can have global git config&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git config --global user.name &amp;quot;First User&amp;quot;
$ git config --global user.email &amp;quot;email@email.com&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then use normal flow to push your code&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git add .
$ git commit -m &amp;quot;your comments&amp;quot;
$ git push
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In fact, if I wanted to I could have a different SSH key for every account I have; GitHub, Bitbucket, or any other service that requires one.&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Tips To Delete Remote And Local Branch From Git</title>
   <link href="http://vparihar01.github.io/tips/2012/12/21/Tips-to-delete-remote-and-local-branch-from-git"/>
   <updated>2012-12-21T00:00:00+05:30</updated>
   <id>http://vparihar01.github.io/tips/2012/12/21/Tips-to-delete-remote-and-local-branch-from-git</id>
   <content type="html">&lt;p&gt;Tips to delete, remote and local branch from &lt;strong&gt;&lt;em&gt;GIT&lt;/em&gt;&lt;/strong&gt; e.g &lt;strong&gt;&lt;em&gt;github&lt;/em&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;em&gt;bucket&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Deleting a remote as well as a local branch from git is pretty simple.&lt;/p&gt;

&lt;h3 id='to_delete_a_remote_branch_'&gt;To delete a remote branch -:&lt;/h3&gt;

&lt;h4 id='step_1_just_go_into_your_project_directory_from_consolegitbashif_you_are_using_windows'&gt;Step 1: Just go into your project directory from console/gitbash(if you are using windows)&lt;/h4&gt;

&lt;p&gt;In console enter-:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
$ git branch -r
&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You see a list of the remote branches .&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;origin/design&lt;/li&gt;

&lt;li&gt;origin/develop&lt;/li&gt;

&lt;li&gt;origin/feature&lt;/li&gt;

&lt;li&gt;origin/master&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id='step_2_if_you_want_to_delete_the_branch_name__from_'&gt;Step 2: If you want to delete the branch name &lt;code&gt;develop&lt;/code&gt; from &lt;code&gt;git(Github)&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;Then enter in the console-:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
$ git push origin :develop
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;(Where &lt;code&gt;origin&lt;/code&gt; is your remote name and &lt;code&gt;develop&lt;/code&gt; is the name of the branch)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The above command will delete the &lt;strong&gt;&lt;em&gt;develop&lt;/em&gt;&lt;/strong&gt; branch on the origin remote&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id='to_delete_a_local_branch_'&gt;To delete a local branch -:&lt;/h3&gt;

&lt;h4 id='step_1_first_make_sure_you_are_not_on_the_same_branch'&gt;Step 1: First, make sure you are not on the same branch&lt;/h4&gt;

&lt;p&gt;(eg. &lt;code&gt;develop&lt;/code&gt;) which you are going to delete from the local repo also. Just move from that branch to another branch using.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
$ git checkout branch_name
&lt;/code&gt;&lt;/p&gt;

&lt;h4 id='step_2_then_enter_in_the_console'&gt;Step 2: Then enter in the console:&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;
$ git branch -d develop
&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This will delete the branch locally as well.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;&amp;#8230;&amp;#8230;&amp;#8230;Well Done&amp;#8230;&amp;#8230;&amp;#8230;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Cleaning Your Git Repo Files And Folders</title>
   <link href="http://vparihar01.github.io/tips/2012/11/03/cleaning-your-git-repo-files-and-folders"/>
   <updated>2012-11-03T00:00:00+05:30</updated>
   <id>http://vparihar01.github.io/tips/2012/11/03/cleaning-your-git-repo-files-and-folders</id>
   <content type="html">&lt;h2 id='cleaning_your_git_repo_files_and_folders_even_remote_ones'&gt;Cleaning your git repo files and folders (even remote ones)&lt;/h2&gt;

&lt;p&gt;To clean unused or orphan files and folders from a &lt;code&gt;github&lt;/code&gt; account is really easy! But very often, people just delete the files/folder from the project manually, using the &lt;code&gt;shift+delete&lt;/code&gt; command and then follow:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
$ git add .
$ git commit -m “whatever”
$ git push origin branch_name.
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;But this doesnt delete the files/folder from git index (or from git repo). Every time you do git status you see lots of deleted files and they are not committed in the console.&lt;/p&gt;

&lt;p&gt;To delete files from git index(or from git repo) as well, just follow the given steps :-&lt;/p&gt;

&lt;h3 id='step_1_remove_files_and_directories_from_git_index'&gt;Step 1: Remove files and directories from git index&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;
$ git -rm file_name
&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This will remove files from the working tree (local) and from the index (from git repo)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;or to remove the folder&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
$ git -rm -rf folder_name
&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This will remove the folder from the working tree (local) and from the index (from git repo). &lt;code&gt;-r&lt;/code&gt; allows recursive removal when a leading directoryname is given.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id='step_2_commit_and_push_the_changes_to_github'&gt;Step 2: Commit and push the changes to github.&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;
$ git add .
&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This command updates the index using the current content found in the working tree, to prepare the content staged for the next commit.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;
$ git commit -m &amp;quot;write your any comment here&amp;quot;
&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This command stores the current contents of the index in a new commit along with a log message from the user describing the changes.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;
$ git push origin branch_name
&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This command Updates remote refs using local refs,while ending objects necessary to complete the given refs.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;You are done and your directory is neat and clean!&lt;/em&gt;&lt;/p&gt;</content>
 </entry>
 
 
</feed>